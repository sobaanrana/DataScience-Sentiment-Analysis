{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muhammad Hammad Latif   FA18-BCS-134\n",
    "## Rana Muhammad Sobaan    FA18-BCS-038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Training Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are using _ as a seperator/ delimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity\n",
       "0      0             time to eat with my best buddy! #lunch    Happy\n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy\n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy\n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad\n",
       "4      4                                 loved my work!!!!!    Happy\n",
       "5      5        Worst customer care service......@@$$$angry      Sad\n",
       "6      6                           Brilliant effort guys!!!    Happy\n",
       "7      7  @user @user you point one finger @user million...      Sad\n",
       "8      8  words r free, it's how u use that can cost you...    Happy\n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.read_csv(\"TrainData.csv\",\"_\")\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad\n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy\n",
       "2      2  @user when you're blocked by a troll because y...      Sad\n",
       "3      3                               dinner with sister!!    Happy\n",
       "4      4   who else is planning on watching @user tomorrow?    happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = pd.read_csv(\"TestData.csv\",\"_\")\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to remove @user in the data\n",
    "\n",
    "def remove_pattern(text,pattern):\n",
    "    \n",
    "    # re.findall() finds the pattern i.e @user and creating list\n",
    "    r = re.findall(pattern,text)\n",
    "    \n",
    "    # re.sub() removes @user from the sentences in the dataset\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying function to both datasets for removing @user\n",
    "\n",
    "trainData['Processed_Comment'] = np.vectorize(remove_pattern)(trainData['Comment'], \"@[\\w]*\")\n",
    "\n",
    "testData['Processed_Comment'] = np.vectorize(remove_pattern)(testData['Comment'], \"@[\\w]*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ec126bf61b6b>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trainData['Processed_Comment'] = trainData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time to eat with my best buddy   lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>if they want reflection money   ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good job but I  will expect a lot more in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service      nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service         angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger  millions are pointed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words r free  it s how u use that can cost you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might be a libtard if     libtard  sjw  li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0             time to eat with my best buddy   lunch  \n",
       "1              if they want reflection money   ksleg  \n",
       "2     Good job but I  will expect a lot more in f...  \n",
       "3  totally dissatisfied with the service      nev...  \n",
       "4                                 loved my work       \n",
       "5          Worst customer care service         angry  \n",
       "6                           Brilliant effort guys     \n",
       "7    you point one finger  millions are pointed r...  \n",
       "8  words r free  it s how u use that can cost you...  \n",
       "9  you might be a libtard if     libtard  sjw  li...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything except text i.e letters/words\n",
    "\n",
    "trainData['Processed_Comment'] = trainData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-01d6dab056a2>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  testData['Processed_Comment'] = testData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night      faith ever  vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when you re blocked by a troll because you pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "      <td>who else is planning on watching  tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0   the pic says otherwise for young girls confin...  \n",
       "1     good night      faith ever  vaitacacommafiasdv  \n",
       "2   when you re blocked by a troll because you pr...  \n",
       "3                               dinner with sister    \n",
       "4        who else is planning on watching  tomorrow   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything except text i.e letters/words\n",
    "\n",
    "testData['Processed_Comment'] = testData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time eat with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good job but will expect lot more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service never us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger millions are pointed righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words free how use that can cost you verbal ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might libtard libtard sjw liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                     time eat with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2           Good job but will expect lot more future  \n",
       "3  totally dissatisfied with the service never us...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  you point one finger millions are pointed righ...  \n",
       "8  words free how use that can cost you verbal ab...  \n",
       "9     you might libtard libtard sjw liberal politics  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Short Words\n",
    "trainData['Processed_Comment'] = trainData['Processed_Comment'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>=3]))\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when you blocked troll because you promise bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "      <td>who else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  the pic says otherwise for young girls confine...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when you blocked troll because you promise bla...  \n",
       "3                                 dinner with sister  \n",
       "4                who else planning watching tomorrow  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Short Words\n",
    "testData['Processed_Comment'] = testData['Processed_Comment'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>=3]))\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Making sure that all Happy and Sad are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time eat with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good job but will expect lot more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service never us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger millions are pointed righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words free how use that can cost you verbal ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might libtard libtard sjw liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                     time eat with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2           Good job but will expect lot more future  \n",
       "3  totally dissatisfied with the service never us...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  you point one finger millions are pointed righ...  \n",
       "8  words free how use that can cost you verbal ab...  \n",
       "9     you might libtard libtard sjw liberal politics  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['Polarity'] = trainData['Polarity'].apply(lambda x: x.capitalize())\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when you blocked troll because you promise bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>who else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  the pic says otherwise for young girls confine...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when you blocked troll because you promise bla...  \n",
       "3                                 dinner with sister  \n",
       "4                who else planning watching tomorrow  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['Polarity'] = testData['Polarity'].apply(lambda x: x.capitalize())\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding for Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(polarity):\n",
    "    if(polarity == 'Happy'):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time eat with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good job but will expect lot more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>totally dissatisfied with the service never us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>you point one finger millions are pointed righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>words free how use that can cost you verbal ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>you might libtard libtard sjw liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch         1   \n",
       "1      1  @user @user if they want reflection money. #ksleg         1   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4      4                                 loved my work!!!!!         1   \n",
       "5      5        Worst customer care service......@@$$$angry         0   \n",
       "6      6                           Brilliant effort guys!!!         1   \n",
       "7      7  @user @user you point one finger @user million...         0   \n",
       "8      8  words r free, it's how u use that can cost you...         1   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                     time eat with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2           Good job but will expect lot more future  \n",
       "3  totally dissatisfied with the service never us...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  you point one finger millions are pointed righ...  \n",
       "8  words free how use that can cost you verbal ab...  \n",
       "9     you might libtard libtard sjw liberal politics  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['Polarity'] = trainData['Polarity'].apply(lambda x: labelEncoder(x))\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>the pic says otherwise for young girls confine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when you blocked troll because you promise bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>who else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...         0   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2      2  @user when you're blocked by a troll because y...         0   \n",
       "3      3                               dinner with sister!!         1   \n",
       "4      4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  the pic says otherwise for young girls confine...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when you blocked troll because you promise bla...  \n",
       "3                                 dinner with sister  \n",
       "4                who else planning watching tomorrow  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['Polarity'] = testData['Polarity'].apply(lambda x: labelEncoder(x))\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokanizing Comments of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [time, eat, with, best, buddy, lunch]\n",
       "1               [they, want, reflection, money, ksleg]\n",
       "2    [Good, job, but, will, expect, lot, more, future]\n",
       "3    [totally, dissatisfied, with, the, service, ne...\n",
       "4                                        [loved, work]\n",
       "5              [Worst, customer, care, service, angry]\n",
       "6                            [Brilliant, effort, guys]\n",
       "7    [you, point, one, finger, millions, are, point...\n",
       "8    [words, free, how, use, that, can, cost, you, ...\n",
       "9    [you, might, libtard, libtard, sjw, liberal, p...\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_trainComment = trainData['Processed_Comment'].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_trainComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('best', 'JJS'),\n",
       " ('buddy', 'NN'),\n",
       " ('lunch', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('reflection', 'NN'),\n",
       " ('money', 'NN'),\n",
       " ('ksleg', 'NN'),\n",
       " ('Good', 'JJ'),\n",
       " ('job', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('will', 'MD'),\n",
       " ('expect', 'VB'),\n",
       " ('lot', 'NN'),\n",
       " ('more', 'JJR'),\n",
       " ('future', 'JJ'),\n",
       " ('totally', 'RB'),\n",
       " ('dissatisfied', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('service', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('used', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('again', 'RB'),\n",
       " ('loved', 'VBN'),\n",
       " ('work', 'NN'),\n",
       " ('Worst', 'NNP'),\n",
       " ('customer', 'NN'),\n",
       " ('care', 'NN'),\n",
       " ('angry', 'JJ'),\n",
       " ('Brilliant', 'JJ'),\n",
       " ('effort', 'NN'),\n",
       " ('guys', 'NNS'),\n",
       " ('you', 'PRP'),\n",
       " ('point', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('finger', 'NN'),\n",
       " ('millions', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('pointed', 'VBN'),\n",
       " ('right', 'RB'),\n",
       " ('back', 'RB'),\n",
       " ('jewishsupremacist', 'VBP'),\n",
       " ('words', 'NNS'),\n",
       " ('free', 'JJ'),\n",
       " ('how', 'WRB'),\n",
       " ('use', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('can', 'MD'),\n",
       " ('cost', 'VB'),\n",
       " ('verbal', 'JJ'),\n",
       " ('abuse', 'IN'),\n",
       " ('love', 'NN'),\n",
       " ('adult', 'NN'),\n",
       " ('teen', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('libtard', 'VB'),\n",
       " ('libtard', 'NN'),\n",
       " ('sjw', 'JJ'),\n",
       " ('liberal', 'JJ'),\n",
       " ('politics', 'NNS')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "trainDataList = trainData['Processed_Comment'].tolist()\n",
    "taggedList = list()\n",
    "posList = list()\n",
    "\n",
    "for sentence in trainDataList:\n",
    "        tokenized = nltk.word_tokenize(sentence)\n",
    "        taggedList.append(nltk.pos_tag(tokenized))\n",
    "  \n",
    "#removing repititions\n",
    "for tList in taggedList:\n",
    "    for word_tuple in tList:\n",
    "        if word_tuple not in posList:\n",
    "            posList.append(word_tuple)\n",
    "        \n",
    "posList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing additional letters such as ed, 's etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [time, eat, with, best, buddi, lunch]\n",
       "1                  [they, want, reflect, money, ksleg]\n",
       "2     [good, job, but, will, expect, lot, more, futur]\n",
       "3    [total, dissatisfi, with, the, servic, never, ...\n",
       "4                                         [love, work]\n",
       "5                 [worst, custom, care, servic, angri]\n",
       "6                             [brilliant, effort, guy]\n",
       "7    [you, point, one, finger, million, are, point,...\n",
       "8    [word, free, how, use, that, can, cost, you, v...\n",
       "9    [you, might, libtard, libtard, sjw, liber, polit]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_trainComment = tokenized_trainComment.apply(lambda x: [ps.stem(i) for i in x])\n",
    "\n",
    "tokenized_trainComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing old Processed comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time eat with best buddi lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflect money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>good job but will expect lot more futur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>total dissatisfi with the servic never use thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>love work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>worst custom care servic angri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant effort guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>you point one finger million are point right b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>word free how use that can cost you verbal abu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>you might libtard libtard sjw liber polit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch         1   \n",
       "1      1  @user @user if they want reflection money. #ksleg         1   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4      4                                 loved my work!!!!!         1   \n",
       "5      5        Worst customer care service......@@$$$angry         0   \n",
       "6      6                           Brilliant effort guys!!!         1   \n",
       "7      7  @user @user you point one finger @user million...         0   \n",
       "8      8  words r free, it's how u use that can cost you...         1   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                     time eat with best buddi lunch  \n",
       "1                      they want reflect money ksleg  \n",
       "2            good job but will expect lot more futur  \n",
       "3  total dissatisfi with the servic never use thi...  \n",
       "4                                          love work  \n",
       "5                     worst custom care servic angri  \n",
       "6                               brilliant effort guy  \n",
       "7  you point one finger million are point right b...  \n",
       "8  word free how use that can cost you verbal abu...  \n",
       "9          you might libtard libtard sjw liber polit  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_trainComment)):\n",
    "    tokenized_trainComment[i] = ' '.join(tokenized_trainComment[i])\n",
    "\n",
    "trainData['Processed_Comment'] = tokenized_trainComment\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokanizing Comments of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, pic, says, otherwise, for, young, girls,...\n",
       "1       [good, night, faith, ever, vaitacacommafiasdv]\n",
       "2    [when, you, blocked, troll, because, you, prom...\n",
       "3                               [dinner, with, sister]\n",
       "4            [who, else, planning, watching, tomorrow]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_testComment = testData[\"Processed_Comment\"].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_testComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('pic', 'NN'),\n",
       " ('says', 'VBZ'),\n",
       " ('otherwise', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('young', 'JJ'),\n",
       " ('girls', 'NNS'),\n",
       " ('confined', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('kitchen', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('void', 'JJ'),\n",
       " ('meaning', 'VBG'),\n",
       " ('beyond', 'IN'),\n",
       " ('cheap', 'JJ'),\n",
       " ('publicity', 'NN'),\n",
       " ('topoli', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('faith', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('vaitacacommafiasdv', 'VBD'),\n",
       " ('when', 'WRB'),\n",
       " ('blocked', 'VBD'),\n",
       " ('troll', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('promise', 'VBP'),\n",
       " ('blacklivesmatter', 'JJ'),\n",
       " ('amp', 'NN'),\n",
       " ('let', 'VB'),\n",
       " ('his', 'PRP$'),\n",
       " ('nonsensical', 'JJ'),\n",
       " ('rants', 'NNS'),\n",
       " ('dinner', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('sister', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('else', 'RB'),\n",
       " ('planning', 'VBG'),\n",
       " ('watching', 'VBG'),\n",
       " ('tomorrow', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "testDataList = testData['Processed_Comment'].tolist()\n",
    "taggedList = list()\n",
    "posList = list()\n",
    "\n",
    "for sentence in testDataList:\n",
    "        tokenized = nltk.word_tokenize(sentence)\n",
    "        taggedList.append(nltk.pos_tag(tokenized))\n",
    "  \n",
    "#removing repititions\n",
    "for tList in taggedList:\n",
    "    for word_tuple in tList:\n",
    "        if word_tuple not in posList:\n",
    "            posList.append(word_tuple)\n",
    "        \n",
    "posList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing additional letters such as ed, 's etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [the, pic, say, otherwis, for, young, girl, co...\n",
       "1       [good, night, faith, ever, vaitacacommafiasdv]\n",
       "2    [when, you, block, troll, becaus, you, promis,...\n",
       "3                               [dinner, with, sister]\n",
       "4                    [who, els, plan, watch, tomorrow]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_testComment = tokenized_testComment.apply(lambda x : [ps.stem(i) for i in x])\n",
    "\n",
    "\n",
    "tokenized_testComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing old Processed comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>the pic say otherwis for young girl confin tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when you block troll becaus you promis blackli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>who els plan watch tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...         0   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2      2  @user when you're blocked by a troll because y...         0   \n",
       "3      3                               dinner with sister!!         1   \n",
       "4      4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  the pic say otherwis for young girl confin tha...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when you block troll becaus you promis blackli...  \n",
       "3                                 dinner with sister  \n",
       "4                        who els plan watch tomorrow  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_testComment)):\n",
    "    tokenized_testComment[i] = ' '.join(tokenized_testComment[i])\n",
    "    \n",
    "testData['Processed_Comment'] = tokenized_testComment\n",
    "    \n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 49, 'eat': 15, 'with': 55, 'best': 6, 'buddi': 8, 'lunch': 31, 'they': 47, 'want': 53, 'reflect': 40, 'money': 34, 'ksleg': 26, 'good': 21, 'job': 25, 'but': 9, 'will': 54, 'expect': 17, 'lot': 29, 'more': 35, 'futur': 20, 'total': 50, 'dissatisfi': 14, 'the': 46, 'servic': 42, 'never': 36, 'use': 51, 'thi': 48, 'again': 2, 'love': 30, 'work': 57, 'worst': 58, 'custom': 13, 'care': 11, 'angri': 3, 'brilliant': 7, 'effort': 16, 'guy': 22, 'you': 59, 'point': 38, 'one': 37, 'finger': 18, 'million': 33, 'are': 4, 'right': 41, 'back': 5, 'jewishsupremacist': 24, 'word': 56, 'free': 19, 'how': 23, 'that': 45, 'can': 10, 'cost': 12, 'verbal': 52, 'abus': 0, 'adult': 1, 'teen': 44, 'might': 32, 'libtard': 28, 'sjw': 43, 'liber': 27, 'polit': 39}\n",
      "['abus', 'adult', 'again', 'angri', 'are', 'back', 'best', 'brilliant', 'buddi', 'but', 'can', 'care', 'cost', 'custom', 'dissatisfi', 'eat', 'effort', 'expect', 'finger', 'free', 'futur', 'good', 'guy', 'how', 'jewishsupremacist', 'job', 'ksleg', 'liber', 'libtard', 'lot', 'love', 'lunch', 'might', 'million', 'money', 'more', 'never', 'one', 'point', 'polit', 'reflect', 'right', 'servic', 'sjw', 'teen', 'that', 'the', 'they', 'thi', 'time', 'total', 'use', 'verbal', 'want', 'will', 'with', 'word', 'work', 'worst', 'you']\n",
      "\n",
      "\n",
      "[[0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 2 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 1 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      " [1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 1 0 0 0\n",
      "  0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_train = cv.fit_transform(trainData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.418024</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.418024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311046</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27511</td>\n",
       "      <td>0.27511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.288694</td>\n",
       "      <td>0.288694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245416</td>\n",
       "      <td>0.288694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3        4        5         6   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.418024   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "3  0.000000  0.000000  0.311046  0.000000  0.00000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.460158  0.00000  0.00000  0.000000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.27511  0.27511  0.000000   \n",
       "8  0.288694  0.288694  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "\n",
       "        7         8         9   ...        50        51        52        53  \\\n",
       "0  0.00000  0.418024  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.447214   \n",
       "2  0.00000  0.000000  0.353553  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.00000  0.000000  0.000000  ...  0.311046  0.264418  0.000000  0.000000   \n",
       "4  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.57735  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.00000  0.000000  0.000000  ...  0.000000  0.245416  0.288694  0.000000   \n",
       "9  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.000000  0.355359  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.353553  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.264418  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.761905  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.460158  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.409215  \n",
       "8  0.000000  0.000000  0.288694  0.000000  0.000000  0.214710  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.254304  \n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(trainData['Processed_Comment'])\n",
    "\n",
    "trainData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(trainData_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'eat', 'with'),\n",
       " ('eat', 'with', 'best'),\n",
       " ('with', 'best', 'buddi'),\n",
       " ('best', 'buddi', 'lunch'),\n",
       " ('they', 'want', 'reflect'),\n",
       " ('want', 'reflect', 'money'),\n",
       " ('reflect', 'money', 'ksleg'),\n",
       " ('good', 'job', 'but'),\n",
       " ('job', 'but', 'will'),\n",
       " ('but', 'will', 'expect'),\n",
       " ('will', 'expect', 'lot'),\n",
       " ('expect', 'lot', 'more'),\n",
       " ('lot', 'more', 'futur'),\n",
       " ('total', 'dissatisfi', 'with'),\n",
       " ('dissatisfi', 'with', 'the'),\n",
       " ('with', 'the', 'servic'),\n",
       " ('the', 'servic', 'never'),\n",
       " ('servic', 'never', 'use'),\n",
       " ('never', 'use', 'thi'),\n",
       " ('use', 'thi', 'servic'),\n",
       " ('thi', 'servic', 'again'),\n",
       " ('worst', 'custom', 'care'),\n",
       " ('custom', 'care', 'servic'),\n",
       " ('care', 'servic', 'angri'),\n",
       " ('brilliant', 'effort', 'guy'),\n",
       " ('you', 'point', 'one'),\n",
       " ('point', 'one', 'finger'),\n",
       " ('one', 'finger', 'million'),\n",
       " ('finger', 'million', 'are'),\n",
       " ('million', 'are', 'point'),\n",
       " ('are', 'point', 'right'),\n",
       " ('point', 'right', 'back'),\n",
       " ('right', 'back', 'you'),\n",
       " ('back', 'you', 'jewishsupremacist'),\n",
       " ('word', 'free', 'how'),\n",
       " ('free', 'how', 'use'),\n",
       " ('how', 'use', 'that'),\n",
       " ('use', 'that', 'can'),\n",
       " ('that', 'can', 'cost'),\n",
       " ('can', 'cost', 'you'),\n",
       " ('cost', 'you', 'verbal'),\n",
       " ('you', 'verbal', 'abus'),\n",
       " ('verbal', 'abus', 'love'),\n",
       " ('abus', 'love', 'adult'),\n",
       " ('love', 'adult', 'teen'),\n",
       " ('you', 'might', 'libtard'),\n",
       " ('might', 'libtard', 'libtard'),\n",
       " ('libtard', 'libtard', 'sjw'),\n",
       " ('libtard', 'sjw', 'liber'),\n",
       " ('sjw', 'liber', 'polit')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataList = trainData['Processed_Comment'].tolist()\n",
    "grams = list()\n",
    "n = 3\n",
    "\n",
    "for sentence in trainDataList:\n",
    "    threeGrams = ngrams(sentence.split(), n)\n",
    "    for gram in threeGrams:\n",
    "      grams.append(gram)\n",
    "\n",
    "grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction for Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 30, 'pic': 22, 'say': 27, 'otherwis': 21, 'for': 12, 'young': 41, 'girl': 13, 'confin': 7, 'that': 29, 'kitchen': 16, 'you': 40, 'are': 1, 'void': 35, 'mean': 18, 'beyond': 3, 'cheap': 6, 'public': 25, 'topoli': 32, 'good': 14, 'night': 19, 'faith': 11, 'ever': 10, 'vaitacacommafiasdv': 34, 'when': 37, 'block': 5, 'troll': 33, 'becaus': 2, 'promis': 24, 'blacklivesmatt': 4, 'amp': 0, 'let': 17, 'hi': 15, 'nonsens': 20, 'rant': 26, 'dinner': 8, 'with': 39, 'sister': 28, 'who': 38, 'els': 9, 'plan': 23, 'watch': 36, 'tomorrow': 31}\n",
      "['amp', 'are', 'becaus', 'beyond', 'blacklivesmatt', 'block', 'cheap', 'confin', 'dinner', 'els', 'ever', 'faith', 'for', 'girl', 'good', 'hi', 'kitchen', 'let', 'mean', 'night', 'nonsens', 'otherwis', 'pic', 'plan', 'promis', 'public', 'rant', 'say', 'sister', 'that', 'the', 'tomorrow', 'topoli', 'troll', 'vaitacacommafiasdv', 'void', 'watch', 'when', 'who', 'with', 'you', 'young']\n",
      "\n",
      "\n",
      "[[0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1\n",
      "  0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_test = cv.fit_transform(testData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.192034</td>\n",
       "      <td>0.238022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.437486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000000  0.238022  0.000000  0.238022  0.000000  0.000000  0.238022   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.271127  0.000000  0.271127  0.000000  0.271127  0.271127  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7        8         9   ...        32        33        34        35  \\\n",
       "0  0.238022  0.00000  0.000000  ...  0.238022  0.000000  0.000000  0.238022   \n",
       "1  0.000000  0.00000  0.000000  ...  0.000000  0.000000  0.447214  0.000000   \n",
       "2  0.000000  0.00000  0.000000  ...  0.000000  0.271127  0.000000  0.000000   \n",
       "3  0.000000  0.57735  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.00000  0.447214  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         36        37        38       39        40        41  \n",
       "0  0.000000  0.000000  0.000000  0.00000  0.192034  0.238022  \n",
       "1  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  \n",
       "2  0.000000  0.271127  0.000000  0.00000  0.437486  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.57735  0.000000  0.000000  \n",
       "4  0.447214  0.000000  0.447214  0.00000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(testData['Processed_Comment'])\n",
    "\n",
    "testData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(testData_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'pic', 'say'),\n",
       " ('pic', 'say', 'otherwis'),\n",
       " ('say', 'otherwis', 'for'),\n",
       " ('otherwis', 'for', 'young'),\n",
       " ('for', 'young', 'girl'),\n",
       " ('young', 'girl', 'confin'),\n",
       " ('girl', 'confin', 'that'),\n",
       " ('confin', 'that', 'kitchen'),\n",
       " ('that', 'kitchen', 'you'),\n",
       " ('kitchen', 'you', 'are'),\n",
       " ('you', 'are', 'void'),\n",
       " ('are', 'void', 'mean'),\n",
       " ('void', 'mean', 'beyond'),\n",
       " ('mean', 'beyond', 'cheap'),\n",
       " ('beyond', 'cheap', 'public'),\n",
       " ('cheap', 'public', 'topoli'),\n",
       " ('good', 'night', 'faith'),\n",
       " ('night', 'faith', 'ever'),\n",
       " ('faith', 'ever', 'vaitacacommafiasdv'),\n",
       " ('when', 'you', 'block'),\n",
       " ('you', 'block', 'troll'),\n",
       " ('block', 'troll', 'becaus'),\n",
       " ('troll', 'becaus', 'you'),\n",
       " ('becaus', 'you', 'promis'),\n",
       " ('you', 'promis', 'blacklivesmatt'),\n",
       " ('promis', 'blacklivesmatt', 'amp'),\n",
       " ('blacklivesmatt', 'amp', 'let'),\n",
       " ('amp', 'let', 'hi'),\n",
       " ('let', 'hi', 'nonsens'),\n",
       " ('hi', 'nonsens', 'rant'),\n",
       " ('dinner', 'with', 'sister'),\n",
       " ('who', 'els', 'plan'),\n",
       " ('els', 'plan', 'watch'),\n",
       " ('plan', 'watch', 'tomorrow')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataList = testData['Processed_Comment'].tolist()\n",
    "grams = list()\n",
    "n = 3\n",
    "\n",
    "for sentence in testDataList:\n",
    "    threeGrams = ngrams(sentence.split(), n)\n",
    "    for gram in threeGrams:\n",
    "      grams.append(gram)\n",
    "\n",
    "grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Combine Both train and Test examples so we can have same number of lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time eat with best buddi lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflect money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>good job but will expect lot more futur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>total dissatisfi with the servic never use thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>love work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>worst custom care servic angri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant effort guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>you point one finger million are point right b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>word free how use that can cost you verbal abu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>you might libtard libtard sjw liber polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>the pic say otherwis for young girl confin tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when you block troll becaus you promis blackli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>who els plan watch tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Polarity  \\\n",
       "0             time to eat with my best buddy! #lunch         1   \n",
       "1  @user @user if they want reflection money. #ksleg         1   \n",
       "2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4                                 loved my work!!!!!         1   \n",
       "5        Worst customer care service......@@$$$angry         0   \n",
       "6                           Brilliant effort guys!!!         1   \n",
       "7  @user @user you point one finger @user million...         0   \n",
       "8  words r free, it's how u use that can cost you...         1   \n",
       "9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "0  @use the pic says otherwise for young girls co...         0   \n",
       "1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2  @user when you're blocked by a troll because y...         0   \n",
       "3                               dinner with sister!!         1   \n",
       "4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                     time eat with best buddi lunch  \n",
       "1                      they want reflect money ksleg  \n",
       "2            good job but will expect lot more futur  \n",
       "3  total dissatisfi with the servic never use thi...  \n",
       "4                                          love work  \n",
       "5                     worst custom care servic angri  \n",
       "6                               brilliant effort guy  \n",
       "7  you point one finger million are point right b...  \n",
       "8  word free how use that can cost you verbal abu...  \n",
       "9          you might libtard libtard sjw liber polit  \n",
       "0  the pic say otherwis for young girl confin tha...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when you block troll becaus you promis blackli...  \n",
       "3                                 dinner with sister  \n",
       "4                        who els plan watch tomorrow  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = trainData\n",
    "\n",
    "b = testData\n",
    "\n",
    "allData = pd.concat([a , b])\n",
    "\n",
    "allData = allData.drop(['Index'], axis=1)\n",
    "\n",
    "allData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 76, 'eat': 23, 'with': 90, 'best': 8, 'buddi': 13, 'lunch': 47, 'they': 74, 'want': 85, 'reflect': 65, 'money': 51, 'ksleg': 41, 'good': 34, 'job': 39, 'but': 14, 'will': 89, 'expect': 27, 'lot': 45, 'more': 52, 'futur': 32, 'total': 79, 'dissatisfi': 22, 'the': 73, 'servic': 68, 'never': 53, 'use': 81, 'thi': 75, 'again': 2, 'love': 46, 'work': 92, 'worst': 93, 'custom': 20, 'care': 16, 'angri': 4, 'brilliant': 12, 'effort': 24, 'guy': 35, 'you': 94, 'point': 60, 'one': 56, 'finger': 29, 'million': 50, 'are': 5, 'right': 66, 'back': 6, 'jewishsupremacist': 38, 'word': 91, 'free': 31, 'how': 37, 'that': 72, 'can': 15, 'cost': 19, 'verbal': 83, 'abus': 0, 'adult': 1, 'teen': 71, 'might': 49, 'libtard': 44, 'sjw': 70, 'liber': 43, 'polit': 61, 'pic': 58, 'say': 67, 'otherwis': 57, 'for': 30, 'young': 95, 'girl': 33, 'confin': 18, 'kitchen': 40, 'void': 84, 'mean': 48, 'beyond': 9, 'cheap': 17, 'public': 63, 'topoli': 78, 'night': 54, 'faith': 28, 'ever': 26, 'vaitacacommafiasdv': 82, 'when': 87, 'block': 11, 'troll': 80, 'becaus': 7, 'promis': 62, 'blacklivesmatt': 10, 'amp': 3, 'let': 42, 'hi': 36, 'nonsens': 55, 'rant': 64, 'dinner': 21, 'sister': 69, 'who': 88, 'els': 25, 'plan': 59, 'watch': 86, 'tomorrow': 77}\n",
      "['abus', 'adult', 'again', 'amp', 'angri', 'are', 'back', 'becaus', 'best', 'beyond', 'blacklivesmatt', 'block', 'brilliant', 'buddi', 'but', 'can', 'care', 'cheap', 'confin', 'cost', 'custom', 'dinner', 'dissatisfi', 'eat', 'effort', 'els', 'ever', 'expect', 'faith', 'finger', 'for', 'free', 'futur', 'girl', 'good', 'guy', 'hi', 'how', 'jewishsupremacist', 'job', 'kitchen', 'ksleg', 'let', 'liber', 'libtard', 'lot', 'love', 'lunch', 'mean', 'might', 'million', 'money', 'more', 'never', 'night', 'nonsens', 'one', 'otherwis', 'pic', 'plan', 'point', 'polit', 'promis', 'public', 'rant', 'reflect', 'right', 'say', 'servic', 'sister', 'sjw', 'teen', 'that', 'the', 'they', 'thi', 'time', 'tomorrow', 'topoli', 'total', 'troll', 'use', 'vaitacacommafiasdv', 'verbal', 'void', 'want', 'watch', 'when', 'who', 'will', 'with', 'word', 'work', 'worst', 'you', 'young']\n",
      "\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_all_data = cv.fit_transform(allData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already have frature extraction for both test and train data in bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bag_of_words_all_data[:10]\n",
    "Y_train = allData['Polarity'][0:10]\n",
    "\n",
    "X_test = bag_of_words_all_data[10:]\n",
    "Y_test = allData['Polarity'][10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [0 1 0 1 1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "decisionTree_bag_of_words = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "decisionTree_bag_of_words.fit(X_train , Y_train)\n",
    "Y_pred = decisionTree_bag_of_words.predict(X_test)\n",
    "print('Predicted values: ', end=' ')\n",
    "print(Y_pred)\n",
    "\n",
    "print('Accuracy:' , end=' ')\n",
    "print(accuracy_score(Y_test ,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree through TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.283877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365204</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.292656</td>\n",
       "      <td>0.292656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157519</td>\n",
       "      <td>0.244882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.314278  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.458638  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.246500  0.283877   \n",
       "8   0.292656  0.292656  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.212639  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.281105  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          7         8         9   ...        86        87        88        89  \\\n",
       "0   0.000000  0.422559  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.359118   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.244882  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.281105  0.000000  0.000000  ...  0.000000  0.281105  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.447214  0.000000  0.447214  0.000000   \n",
       "\n",
       "          90        91        92        93        94        95  \n",
       "0   0.327446  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.243537  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.755067  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.458638  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.365204  0.000000  \n",
       "8   0.000000  0.292656  0.000000  0.000000  0.188249  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.221758  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.157519  0.244882  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.361637  0.000000  \n",
       "13  0.480535  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[15 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(allData['Processed_Comment'])\n",
    "\n",
    "allData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(allData_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allData_tfidf[:10]\n",
    "Y_train = allData['Polarity'][0:10]\n",
    "\n",
    "X_test = allData_tfidf[10:]\n",
    "Y_test = allData['Polarity'][10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [1 1 0 1 1]\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "decisionTree_tfidf = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "decisionTree_tfidf.fit(X_train , Y_train)\n",
    "Y_pred = decisionTree_tfidf.predict(X_test)\n",
    "print('Predicted values: ', end=' ')\n",
    "print(Y_pred)\n",
    "\n",
    "print('Accuracy:' , end=' ')\n",
    "print(accuracy_score(Y_test ,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Decision Tree Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_decisionTree = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "full_decisionTree.fit(bag_of_words_all_data[:] , allData['Polarity'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(full_decisionTree, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter A Tweet: they want to kill this sad is it not @someone #eating\n"
     ]
    }
   ],
   "source": [
    "userTweet = input('Enter A Tweet: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTweet = remove_pattern(userTweet , \"@[\\w]*\")\n",
    "\n",
    "r = re.findall(\"[^a-zA-Z]\" , userTweet)\n",
    "text = ''\n",
    "for i in r:\n",
    "    text = re.sub(i,\" \",userTweet)\n",
    "userTweet = text\n",
    "\n",
    "userTweet = userTweet.lower()\n",
    "\n",
    "userTweet = [x for x in userTweet.split() if len(x) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'want', 'kill', 'thi', 'sad', 'not', 'eat']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "for x in range(len(userTweet)):\n",
    "    userTweet[x] = ps.stem(userTweet[x])\n",
    "\n",
    "userTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of Our Feature names are in cv.get_feature_names()\n",
    "\n",
    "lables = cv.get_feature_names()\n",
    "\n",
    "userTweetArr = []\n",
    "\n",
    "for x in lables:\n",
    "    total = 0\n",
    "    for y in userTweet:\n",
    "        if x == y:\n",
    "            total = total + 1\n",
    "    userTweetArr.append(total)\n",
    "\n",
    "predictArr = [userTweetArr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = loaded_model.predict(predictArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tweet Polarity is Happy\n"
     ]
    }
   ],
   "source": [
    "if predict == 1:\n",
    "    print('The Tweet Polarity is Happy')\n",
    "else:\n",
    "    print('The Tweet Polarity is Sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
