{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muhammad Hammad Latif   FA18-BCS-134\n",
    "## Rana Muhammad Sobaan    FA18-BCS-038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Training Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are using _ as a seperator/ delimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity\n",
       "0      0             time to eat with my best buddy! #lunch    Happy\n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy\n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy\n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad\n",
       "4      4                                 loved my work!!!!!    Happy\n",
       "5      5        Worst customer care service......@@$$$angry      Sad\n",
       "6      6                           Brilliant effort guys!!!    Happy\n",
       "7      7  @user @user you point one finger @user million...      Sad\n",
       "8      8  words r free, it's how u use that can cost you...    Happy\n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.read_csv(\"TrainData.csv\",\"_\")\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad\n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy\n",
       "2      2  @user when you're blocked by a troll because y...      Sad\n",
       "3      3                               dinner with sister!!    Happy\n",
       "4      4   who else is planning on watching @user tomorrow?    happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = pd.read_csv(\"TestData.csv\",\"_\")\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to remove @user in the data\n",
    "\n",
    "def remove_pattern(text,pattern):\n",
    "    \n",
    "    # re.findall() finds the pattern i.e @user and creating list\n",
    "    r = re.findall(pattern,text)\n",
    "    \n",
    "    # re.sub() removes @user from the sentences in the dataset\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying function to both datasets for removing @user\n",
    "\n",
    "trainData['Processed_Comment'] = np.vectorize(remove_pattern)(trainData['Comment'], \"@[\\w]*\")\n",
    "\n",
    "testData['Processed_Comment'] = np.vectorize(remove_pattern)(testData['Comment'], \"@[\\w]*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ec126bf61b6b>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trainData['Processed_Comment'] = trainData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time to eat with my best buddy   lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>if they want reflection money   ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good job but I  will expect a lot more in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service      nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service         angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger  millions are pointed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words r free  it s how u use that can cost you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might be a libtard if     libtard  sjw  li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0             time to eat with my best buddy   lunch  \n",
       "1              if they want reflection money   ksleg  \n",
       "2     Good job but I  will expect a lot more in f...  \n",
       "3  totally dissatisfied with the service      nev...  \n",
       "4                                 loved my work       \n",
       "5          Worst customer care service         angry  \n",
       "6                           Brilliant effort guys     \n",
       "7    you point one finger  millions are pointed r...  \n",
       "8  words r free  it s how u use that can cost you...  \n",
       "9  you might be a libtard if     libtard  sjw  li...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything except text i.e letters/words\n",
    "\n",
    "trainData['Processed_Comment'] = trainData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-01d6dab056a2>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  testData['Processed_Comment'] = testData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night      faith ever  vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when you re blocked by a troll because you pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "      <td>who else is planning on watching  tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0   the pic says otherwise for young girls confin...  \n",
       "1     good night      faith ever  vaitacacommafiasdv  \n",
       "2   when you re blocked by a troll because you pr...  \n",
       "3                               dinner with sister    \n",
       "4        who else is planning on watching  tomorrow   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything except text i.e letters/words\n",
    "\n",
    "testData['Processed_Comment'] = testData['Processed_Comment'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good will expect more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with service never used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>point finger millions pointed right back jewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words free that cost verbal abuse love adult teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>might libtard libtard liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                         time with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2                       Good will expect more future  \n",
       "3  totally dissatisfied with service never used t...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  point finger millions pointed right back jewis...  \n",
       "8  words free that cost verbal abuse love adult teen  \n",
       "9             might libtard libtard liberal politics  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Short Words\n",
    "trainData['Processed_Comment'] = trainData['Processed_Comment'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>says otherwise young girls confined that kitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when blocked troll because promise blacklivesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>happy</td>\n",
       "      <td>else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  says otherwise young girls confined that kitch...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when blocked troll because promise blacklivesm...  \n",
       "3                                 dinner with sister  \n",
       "4                    else planning watching tomorrow  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Short Words\n",
    "testData['Processed_Comment'] = testData['Processed_Comment'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Making sure that all Happy and Sad are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good will expect more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with service never used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>point finger millions pointed right back jewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words free that cost verbal abuse love adult teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>might libtard libtard liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch    Happy   \n",
       "1      1  @user @user if they want reflection money. #ksleg    Happy   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4      4                                 loved my work!!!!!    Happy   \n",
       "5      5        Worst customer care service......@@$$$angry      Sad   \n",
       "6      6                           Brilliant effort guys!!!    Happy   \n",
       "7      7  @user @user you point one finger @user million...      Sad   \n",
       "8      8  words r free, it's how u use that can cost you...    Happy   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                         time with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2                       Good will expect more future  \n",
       "3  totally dissatisfied with service never used t...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  point finger millions pointed right back jewis...  \n",
       "8  words free that cost verbal abuse love adult teen  \n",
       "9             might libtard libtard liberal politics  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['Polarity'] = trainData['Polarity'].apply(lambda x: x.capitalize())\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>says otherwise young girls confined that kitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when blocked troll because promise blacklivesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...      Sad   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "2      2  @user when you're blocked by a troll because y...      Sad   \n",
       "3      3                               dinner with sister!!    Happy   \n",
       "4      4   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  says otherwise young girls confined that kitch...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when blocked troll because promise blacklivesm...  \n",
       "3                                 dinner with sister  \n",
       "4                    else planning watching tomorrow  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['Polarity'] = testData['Polarity'].apply(lambda x: x.capitalize())\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding for Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoder(polarity):\n",
    "    if(polarity == 'Happy'):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time with best buddy lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflection money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good will expect more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>totally dissatisfied with service never used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>Worst customer care service angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>point finger millions pointed right back jewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>words free that cost verbal abuse love adult teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>might libtard libtard liberal politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch         1   \n",
       "1      1  @user @user if they want reflection money. #ksleg         1   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4      4                                 loved my work!!!!!         1   \n",
       "5      5        Worst customer care service......@@$$$angry         0   \n",
       "6      6                           Brilliant effort guys!!!         1   \n",
       "7      7  @user @user you point one finger @user million...         0   \n",
       "8      8  words r free, it's how u use that can cost you...         1   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                         time with best buddy lunch  \n",
       "1                   they want reflection money ksleg  \n",
       "2                       Good will expect more future  \n",
       "3  totally dissatisfied with service never used t...  \n",
       "4                                         loved work  \n",
       "5                  Worst customer care service angry  \n",
       "6                              Brilliant effort guys  \n",
       "7  point finger millions pointed right back jewis...  \n",
       "8  words free that cost verbal abuse love adult teen  \n",
       "9             might libtard libtard liberal politics  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['Polarity'] = trainData['Polarity'].apply(lambda x: labelEncoder(x))\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>says otherwise young girls confined that kitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when blocked troll because promise blacklivesm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...         0   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2      2  @user when you're blocked by a troll because y...         0   \n",
       "3      3                               dinner with sister!!         1   \n",
       "4      4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  says otherwise young girls confined that kitch...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when blocked troll because promise blacklivesm...  \n",
       "3                                 dinner with sister  \n",
       "4                    else planning watching tomorrow  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['Polarity'] = testData['Polarity'].apply(lambda x: labelEncoder(x))\n",
    "\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokanizing Comments of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [time, with, best, buddy, lunch]\n",
       "1               [they, want, reflection, money, ksleg]\n",
       "2                   [Good, will, expect, more, future]\n",
       "3    [totally, dissatisfied, with, service, never, ...\n",
       "4                                        [loved, work]\n",
       "5              [Worst, customer, care, service, angry]\n",
       "6                            [Brilliant, effort, guys]\n",
       "7    [point, finger, millions, pointed, right, back...\n",
       "8    [words, free, that, cost, verbal, abuse, love,...\n",
       "9         [might, libtard, libtard, liberal, politics]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_trainComment = trainData['Processed_Comment'].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_trainComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('best', 'JJS'),\n",
       " ('buddy', 'NN'),\n",
       " ('lunch', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('reflection', 'NN'),\n",
       " ('money', 'NN'),\n",
       " ('ksleg', 'NN'),\n",
       " ('Good', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('expect', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('future', 'JJ'),\n",
       " ('totally', 'RB'),\n",
       " ('dissatisfied', 'JJ'),\n",
       " ('service', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('used', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('again', 'RB'),\n",
       " ('loved', 'VBN'),\n",
       " ('work', 'NN'),\n",
       " ('Worst', 'NNP'),\n",
       " ('customer', 'NN'),\n",
       " ('care', 'NN'),\n",
       " ('angry', 'JJ'),\n",
       " ('Brilliant', 'JJ'),\n",
       " ('effort', 'NN'),\n",
       " ('guys', 'NNS'),\n",
       " ('point', 'NN'),\n",
       " ('finger', 'NN'),\n",
       " ('millions', 'NNS'),\n",
       " ('pointed', 'VBD'),\n",
       " ('right', 'JJ'),\n",
       " ('back', 'RB'),\n",
       " ('jewishsupremacist', 'NN'),\n",
       " ('words', 'NNS'),\n",
       " ('free', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('cost', 'NN'),\n",
       " ('verbal', 'JJ'),\n",
       " ('abuse', 'NN'),\n",
       " ('love', 'NN'),\n",
       " ('adult', 'NN'),\n",
       " ('teen', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('libtard', 'RB'),\n",
       " ('libtard', 'VB'),\n",
       " ('liberal', 'JJ'),\n",
       " ('politics', 'NNS')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "trainDataList = trainData['Processed_Comment'].tolist()\n",
    "taggedList = list()\n",
    "posList = list()\n",
    "\n",
    "for sentence in trainDataList:\n",
    "        tokenized = nltk.word_tokenize(sentence)\n",
    "        taggedList.append(nltk.pos_tag(tokenized))\n",
    "  \n",
    "#removing repititions\n",
    "for tList in taggedList:\n",
    "    for word_tuple in tList:\n",
    "        if word_tuple not in posList:\n",
    "            posList.append(word_tuple)\n",
    "        \n",
    "posList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing additional letters such as ed, 's etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [time, with, best, buddi, lunch]\n",
       "1                  [they, want, reflect, money, ksleg]\n",
       "2                    [good, will, expect, more, futur]\n",
       "3    [total, dissatisfi, with, servic, never, use, ...\n",
       "4                                         [love, work]\n",
       "5                 [worst, custom, care, servic, angri]\n",
       "6                             [brilliant, effort, guy]\n",
       "7    [point, finger, million, point, right, back, j...\n",
       "8    [word, free, that, cost, verbal, abus, love, a...\n",
       "9              [might, libtard, libtard, liber, polit]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_trainComment = tokenized_trainComment.apply(lambda x: [ps.stem(i) for i in x])\n",
    "\n",
    "tokenized_trainComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing old Processed comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time with best buddi lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflect money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>good will expect more futur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>total dissatisfi with servic never use thi ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>love work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>worst custom care servic angri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant effort guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>point finger million point right back jewishsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>word free that cost verbal abus love adult teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>might libtard libtard liber polit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0             time to eat with my best buddy! #lunch         1   \n",
       "1      1  @user @user if they want reflection money. #ksleg         1   \n",
       "2      2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3      3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4      4                                 loved my work!!!!!         1   \n",
       "5      5        Worst customer care service......@@$$$angry         0   \n",
       "6      6                           Brilliant effort guys!!!         1   \n",
       "7      7  @user @user you point one finger @user million...         0   \n",
       "8      8  words r free, it's how u use that can cost you...         1   \n",
       "9      9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                         time with best buddi lunch  \n",
       "1                      they want reflect money ksleg  \n",
       "2                        good will expect more futur  \n",
       "3  total dissatisfi with servic never use thi ser...  \n",
       "4                                          love work  \n",
       "5                     worst custom care servic angri  \n",
       "6                               brilliant effort guy  \n",
       "7  point finger million point right back jewishsu...  \n",
       "8    word free that cost verbal abus love adult teen  \n",
       "9                  might libtard libtard liber polit  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_trainComment)):\n",
    "    tokenized_trainComment[i] = ' '.join(tokenized_trainComment[i])\n",
    "\n",
    "trainData['Processed_Comment'] = tokenized_trainComment\n",
    "\n",
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokanizing Comments of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [says, otherwise, young, girls, confined, that...\n",
       "1       [good, night, faith, ever, vaitacacommafiasdv]\n",
       "2    [when, blocked, troll, because, promise, black...\n",
       "3                               [dinner, with, sister]\n",
       "4                 [else, planning, watching, tomorrow]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_testComment = testData[\"Processed_Comment\"].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_testComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('says', 'VBZ'),\n",
       " ('otherwise', 'RB'),\n",
       " ('young', 'JJ'),\n",
       " ('girls', 'NNS'),\n",
       " ('confined', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('kitchen', 'NN'),\n",
       " ('void', 'NN'),\n",
       " ('meaning', 'VBG'),\n",
       " ('beyond', 'IN'),\n",
       " ('cheap', 'JJ'),\n",
       " ('publicity', 'NN'),\n",
       " ('topoli', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('faith', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('vaitacacommafiasdv', 'VBD'),\n",
       " ('when', 'WRB'),\n",
       " ('blocked', 'VBN'),\n",
       " ('troll', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('promise', 'NN'),\n",
       " ('blacklivesmatter', 'NN'),\n",
       " ('nonsensical', 'JJ'),\n",
       " ('rants', 'NNS'),\n",
       " ('dinner', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('sister', 'NN'),\n",
       " ('else', 'RB'),\n",
       " ('planning', 'VBG'),\n",
       " ('watching', 'VBG'),\n",
       " ('tomorrow', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "testDataList = testData['Processed_Comment'].tolist()\n",
    "taggedList = list()\n",
    "posList = list()\n",
    "\n",
    "for sentence in testDataList:\n",
    "        tokenized = nltk.word_tokenize(sentence)\n",
    "        taggedList.append(nltk.pos_tag(tokenized))\n",
    "  \n",
    "#removing repititions\n",
    "for tList in taggedList:\n",
    "    for word_tuple in tList:\n",
    "        if word_tuple not in posList:\n",
    "            posList.append(word_tuple)\n",
    "        \n",
    "posList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing additional letters such as ed, 's etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [say, otherwis, young, girl, confin, that, kit...\n",
       "1       [good, night, faith, ever, vaitacacommafiasdv]\n",
       "2    [when, block, troll, becaus, promis, blacklive...\n",
       "3                               [dinner, with, sister]\n",
       "4                         [els, plan, watch, tomorrow]\n",
       "Name: Processed_Comment, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_testComment = tokenized_testComment.apply(lambda x : [ps.stem(i) for i in x])\n",
    "\n",
    "\n",
    "tokenized_testComment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing old Processed comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>say otherwis young girl confin that kitchen vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when block troll becaus promis blacklivesmatt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>els plan watch tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Comment  Polarity  \\\n",
       "0      0  @use the pic says otherwise for young girls co...         0   \n",
       "1      1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2      2  @user when you're blocked by a troll because y...         0   \n",
       "3      3                               dinner with sister!!         1   \n",
       "4      4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0  say otherwis young girl confin that kitchen vo...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when block troll becaus promis blacklivesmatt ...  \n",
       "3                                 dinner with sister  \n",
       "4                            els plan watch tomorrow  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_testComment)):\n",
    "    tokenized_testComment[i] = ' '.join(tokenized_testComment[i])\n",
    "    \n",
    "testData['Processed_Comment'] = tokenized_testComment\n",
    "    \n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 39, 'with': 45, 'best': 5, 'buddi': 7, 'lunch': 24, 'they': 37, 'want': 43, 'reflect': 32, 'money': 27, 'ksleg': 20, 'good': 17, 'will': 44, 'expect': 13, 'more': 28, 'futur': 16, 'total': 40, 'dissatisfi': 11, 'servic': 34, 'never': 29, 'use': 41, 'thi': 38, 'again': 2, 'love': 23, 'work': 47, 'worst': 48, 'custom': 10, 'care': 8, 'angri': 3, 'brilliant': 6, 'effort': 12, 'guy': 18, 'point': 30, 'finger': 14, 'million': 26, 'right': 33, 'back': 4, 'jewishsupremacist': 19, 'word': 46, 'free': 15, 'that': 36, 'cost': 9, 'verbal': 42, 'abus': 0, 'adult': 1, 'teen': 35, 'might': 25, 'libtard': 22, 'liber': 21, 'polit': 31}\n",
      "['abus', 'adult', 'again', 'angri', 'back', 'best', 'brilliant', 'buddi', 'care', 'cost', 'custom', 'dissatisfi', 'effort', 'expect', 'finger', 'free', 'futur', 'good', 'guy', 'jewishsupremacist', 'ksleg', 'liber', 'libtard', 'love', 'lunch', 'might', 'million', 'money', 'more', 'never', 'point', 'polit', 'reflect', 'right', 'servic', 'teen', 'that', 'they', 'thi', 'time', 'total', 'use', 'verbal', 'want', 'will', 'with', 'word', 'work', 'worst']\n",
      "\n",
      "\n",
      "[[0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      "  0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0\n",
      "  0 0 1 0 1 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 2 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_train = cv.fit_transform(trainData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322526</td>\n",
       "      <td>0.322526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5        6   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.460158  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "3  0.000000  0.000000  0.322526  0.000000  0.000000  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "5  0.000000  0.000000  0.000000  0.460158  0.000000  0.000000  0.00000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.57735   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.333333  0.000000  0.00000   \n",
       "8  0.338591  0.338591  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "         7         8         9   ...        39        40        41        42  \\\n",
       "0  0.460158  0.000000  0.000000  ...  0.460158  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.322526  0.322526  0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.460158  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.000000  0.000000  0.338591  ...  0.000000  0.000000  0.000000  0.338591   \n",
       "9  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         43        44        45        46        47        48  \n",
       "0  0.000000  0.000000  0.391176  0.000000  0.000000  0.000000  \n",
       "1  0.447214  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.447214  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.274176  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.761905  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.460158  \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8  0.000000  0.000000  0.000000  0.338591  0.000000  0.000000  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(trainData['Processed_Comment'])\n",
    "\n",
    "trainData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(trainData_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'with', 'best'),\n",
       " ('with', 'best', 'buddi'),\n",
       " ('best', 'buddi', 'lunch'),\n",
       " ('they', 'want', 'reflect'),\n",
       " ('want', 'reflect', 'money'),\n",
       " ('reflect', 'money', 'ksleg'),\n",
       " ('good', 'will', 'expect'),\n",
       " ('will', 'expect', 'more'),\n",
       " ('expect', 'more', 'futur'),\n",
       " ('total', 'dissatisfi', 'with'),\n",
       " ('dissatisfi', 'with', 'servic'),\n",
       " ('with', 'servic', 'never'),\n",
       " ('servic', 'never', 'use'),\n",
       " ('never', 'use', 'thi'),\n",
       " ('use', 'thi', 'servic'),\n",
       " ('thi', 'servic', 'again'),\n",
       " ('worst', 'custom', 'care'),\n",
       " ('custom', 'care', 'servic'),\n",
       " ('care', 'servic', 'angri'),\n",
       " ('brilliant', 'effort', 'guy'),\n",
       " ('point', 'finger', 'million'),\n",
       " ('finger', 'million', 'point'),\n",
       " ('million', 'point', 'right'),\n",
       " ('point', 'right', 'back'),\n",
       " ('right', 'back', 'jewishsupremacist'),\n",
       " ('word', 'free', 'that'),\n",
       " ('free', 'that', 'cost'),\n",
       " ('that', 'cost', 'verbal'),\n",
       " ('cost', 'verbal', 'abus'),\n",
       " ('verbal', 'abus', 'love'),\n",
       " ('abus', 'love', 'adult'),\n",
       " ('love', 'adult', 'teen'),\n",
       " ('might', 'libtard', 'libtard'),\n",
       " ('libtard', 'libtard', 'liber'),\n",
       " ('libtard', 'liber', 'polit')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataList = trainData['Processed_Comment'].tolist()\n",
    "grams = list()\n",
    "n = 3\n",
    "\n",
    "for sentence in trainDataList:\n",
    "    threeGrams = ngrams(sentence.split(), n)\n",
    "    for gram in threeGrams:\n",
    "      grams.append(gram)\n",
    "\n",
    "grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction for Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'say': 21, 'otherwis': 16, 'young': 32, 'girl': 10, 'confin': 5, 'that': 23, 'kitchen': 12, 'void': 28, 'mean': 13, 'beyond': 1, 'cheap': 4, 'public': 19, 'topoli': 25, 'good': 11, 'night': 14, 'faith': 9, 'ever': 8, 'vaitacacommafiasdv': 27, 'when': 30, 'block': 3, 'troll': 26, 'becaus': 0, 'promis': 18, 'blacklivesmatt': 2, 'nonsens': 15, 'rant': 20, 'dinner': 6, 'with': 31, 'sister': 22, 'els': 7, 'plan': 17, 'watch': 29, 'tomorrow': 24}\n",
      "['becaus', 'beyond', 'blacklivesmatt', 'block', 'cheap', 'confin', 'dinner', 'els', 'ever', 'faith', 'girl', 'good', 'kitchen', 'mean', 'night', 'nonsens', 'otherwis', 'plan', 'promis', 'public', 'rant', 'say', 'sister', 'that', 'tomorrow', 'topoli', 'troll', 'vaitacacommafiasdv', 'void', 'watch', 'when', 'with', 'young']\n",
      "\n",
      "\n",
      "[[0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_test = cv.fit_transform(testData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.27735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1         2         3        4        5        6    7   \\\n",
       "0  0.000000  0.27735  0.000000  0.000000  0.27735  0.27735  0.00000  0.0   \n",
       "1  0.000000  0.00000  0.000000  0.000000  0.00000  0.00000  0.00000  0.0   \n",
       "2  0.353553  0.00000  0.353553  0.353553  0.00000  0.00000  0.00000  0.0   \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.00000  0.00000  0.57735  0.0   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.00000  0.00000  0.00000  0.5   \n",
       "\n",
       "         8         9   ...       23   24       25        26        27  \\\n",
       "0  0.000000  0.000000  ...  0.27735  0.0  0.27735  0.000000  0.000000   \n",
       "1  0.447214  0.447214  ...  0.00000  0.0  0.00000  0.000000  0.447214   \n",
       "2  0.000000  0.000000  ...  0.00000  0.0  0.00000  0.353553  0.000000   \n",
       "3  0.000000  0.000000  ...  0.00000  0.0  0.00000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  ...  0.00000  0.5  0.00000  0.000000  0.000000   \n",
       "\n",
       "        28   29        30       31       32  \n",
       "0  0.27735  0.0  0.000000  0.00000  0.27735  \n",
       "1  0.00000  0.0  0.000000  0.00000  0.00000  \n",
       "2  0.00000  0.0  0.353553  0.00000  0.00000  \n",
       "3  0.00000  0.0  0.000000  0.57735  0.00000  \n",
       "4  0.00000  0.5  0.000000  0.00000  0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(testData['Processed_Comment'])\n",
    "\n",
    "testData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(testData_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 'otherwis', 'young'),\n",
       " ('otherwis', 'young', 'girl'),\n",
       " ('young', 'girl', 'confin'),\n",
       " ('girl', 'confin', 'that'),\n",
       " ('confin', 'that', 'kitchen'),\n",
       " ('that', 'kitchen', 'void'),\n",
       " ('kitchen', 'void', 'mean'),\n",
       " ('void', 'mean', 'beyond'),\n",
       " ('mean', 'beyond', 'cheap'),\n",
       " ('beyond', 'cheap', 'public'),\n",
       " ('cheap', 'public', 'topoli'),\n",
       " ('good', 'night', 'faith'),\n",
       " ('night', 'faith', 'ever'),\n",
       " ('faith', 'ever', 'vaitacacommafiasdv'),\n",
       " ('when', 'block', 'troll'),\n",
       " ('block', 'troll', 'becaus'),\n",
       " ('troll', 'becaus', 'promis'),\n",
       " ('becaus', 'promis', 'blacklivesmatt'),\n",
       " ('promis', 'blacklivesmatt', 'nonsens'),\n",
       " ('blacklivesmatt', 'nonsens', 'rant'),\n",
       " ('dinner', 'with', 'sister'),\n",
       " ('els', 'plan', 'watch'),\n",
       " ('plan', 'watch', 'tomorrow')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataList = testData['Processed_Comment'].tolist()\n",
    "grams = list()\n",
    "n = 3\n",
    "\n",
    "for sentence in testDataList:\n",
    "    threeGrams = ngrams(sentence.split(), n)\n",
    "    for gram in threeGrams:\n",
    "      grams.append(gram)\n",
    "\n",
    "grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Combine Both train and Test examples so we can have same number of lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Processed_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>1</td>\n",
       "      <td>time with best buddi lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>1</td>\n",
       "      <td>they want reflect money ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>good will expect more futur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>0</td>\n",
       "      <td>total dissatisfi with servic never use thi ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>love work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>0</td>\n",
       "      <td>worst custom care servic angri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>brilliant effort guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>0</td>\n",
       "      <td>point finger million point right back jewishsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>1</td>\n",
       "      <td>word free that cost verbal abus love adult teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>0</td>\n",
       "      <td>might libtard libtard liber polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@use the pic says otherwise for young girls co...</td>\n",
       "      <td>0</td>\n",
       "      <td>say otherwis young girl confin that kitchen vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>1</td>\n",
       "      <td>good night faith ever vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>when block troll becaus promis blacklivesmatt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>1</td>\n",
       "      <td>els plan watch tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Polarity  \\\n",
       "0             time to eat with my best buddy! #lunch         1   \n",
       "1  @user @user if they want reflection money. #ksleg         1   \n",
       "2  ---Good job but I’ will expect a lot more in f...         1   \n",
       "3  totally dissatisfied with the service###%%@@ n...         0   \n",
       "4                                 loved my work!!!!!         1   \n",
       "5        Worst customer care service......@@$$$angry         0   \n",
       "6                           Brilliant effort guys!!!         1   \n",
       "7  @user @user you point one finger @user million...         0   \n",
       "8  words r free, it's how u use that can cost you...         1   \n",
       "9  you might be a libtard if... #libtard #sjw #li...         0   \n",
       "0  @use the pic says otherwise for young girls co...         0   \n",
       "1    #good night! ?? #faith ever #vaitacacommafiasdv         1   \n",
       "2  @user when you're blocked by a troll because y...         0   \n",
       "3                               dinner with sister!!         1   \n",
       "4   who else is planning on watching @user tomorrow?         1   \n",
       "\n",
       "                                   Processed_Comment  \n",
       "0                         time with best buddi lunch  \n",
       "1                      they want reflect money ksleg  \n",
       "2                        good will expect more futur  \n",
       "3  total dissatisfi with servic never use thi ser...  \n",
       "4                                          love work  \n",
       "5                     worst custom care servic angri  \n",
       "6                               brilliant effort guy  \n",
       "7  point finger million point right back jewishsu...  \n",
       "8    word free that cost verbal abus love adult teen  \n",
       "9                  might libtard libtard liber polit  \n",
       "0  say otherwis young girl confin that kitchen vo...  \n",
       "1           good night faith ever vaitacacommafiasdv  \n",
       "2  when block troll becaus promis blacklivesmatt ...  \n",
       "3                                 dinner with sister  \n",
       "4                            els plan watch tomorrow  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = trainData\n",
    "\n",
    "b = testData\n",
    "\n",
    "allData = pd.concat([a , b])\n",
    "\n",
    "allData = allData.drop(['Index'], axis=1)\n",
    "\n",
    "allData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 61, 'with': 74, 'best': 6, 'buddi': 11, 'lunch': 36, 'they': 59, 'want': 70, 'reflect': 52, 'money': 40, 'ksleg': 32, 'good': 28, 'will': 73, 'expect': 22, 'more': 41, 'futur': 26, 'total': 64, 'dissatisfi': 18, 'servic': 55, 'never': 42, 'use': 66, 'thi': 60, 'again': 2, 'love': 35, 'work': 76, 'worst': 77, 'custom': 16, 'care': 12, 'angri': 3, 'brilliant': 10, 'effort': 19, 'guy': 29, 'point': 47, 'finger': 24, 'million': 39, 'right': 53, 'back': 4, 'jewishsupremacist': 30, 'word': 75, 'free': 25, 'that': 58, 'cost': 15, 'verbal': 68, 'abus': 0, 'adult': 1, 'teen': 57, 'might': 38, 'libtard': 34, 'liber': 33, 'polit': 48, 'say': 54, 'otherwis': 45, 'young': 78, 'girl': 27, 'confin': 14, 'kitchen': 31, 'void': 69, 'mean': 37, 'beyond': 7, 'cheap': 13, 'public': 50, 'topoli': 63, 'night': 43, 'faith': 23, 'ever': 21, 'vaitacacommafiasdv': 67, 'when': 72, 'block': 9, 'troll': 65, 'becaus': 5, 'promis': 49, 'blacklivesmatt': 8, 'nonsens': 44, 'rant': 51, 'dinner': 17, 'sister': 56, 'els': 20, 'plan': 46, 'watch': 71, 'tomorrow': 62}\n",
      "['abus', 'adult', 'again', 'angri', 'back', 'becaus', 'best', 'beyond', 'blacklivesmatt', 'block', 'brilliant', 'buddi', 'care', 'cheap', 'confin', 'cost', 'custom', 'dinner', 'dissatisfi', 'effort', 'els', 'ever', 'expect', 'faith', 'finger', 'free', 'futur', 'girl', 'good', 'guy', 'jewishsupremacist', 'kitchen', 'ksleg', 'liber', 'libtard', 'love', 'lunch', 'mean', 'might', 'million', 'money', 'more', 'never', 'night', 'nonsens', 'otherwis', 'plan', 'point', 'polit', 'promis', 'public', 'rant', 'reflect', 'right', 'say', 'servic', 'sister', 'teen', 'that', 'they', 'thi', 'time', 'tomorrow', 'topoli', 'total', 'troll', 'use', 'vaitacacommafiasdv', 'verbal', 'void', 'want', 'watch', 'when', 'will', 'with', 'word', 'work', 'worst', 'young']\n",
      "\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "\n",
    "bag_of_words_all_data = cv.fit_transform(allData['Processed_Comment']).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print('\\n')\n",
    "print(bag_of_words_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already have frature extraction for both test and train data in bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bag_of_words_all_data[:10]\n",
    "Y_train = allData['Polarity'][0:10]\n",
    "\n",
    "X_test = bag_of_words_all_data[10:]\n",
    "Y_test = allData['Polarity'][10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [1 1 1 1 1]\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "decisionTree_bag_of_words = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "decisionTree_bag_of_words.fit(X_train , Y_train)\n",
    "Y_pred = decisionTree_bag_of_words.predict(X_test)\n",
    "print('Predicted values: ', end=' ')\n",
    "print(Y_pred)\n",
    "\n",
    "print('Accuracy:' , end=' ')\n",
    "print(accuracy_score(Y_test ,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree through TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.342836</td>\n",
       "      <td>0.342836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.466228   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.322472  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.458638  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.333333  0.000000  0.000000   \n",
       "8   0.342836  0.342836  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.353553  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          7         8         9   ...        69        70   71        72  \\\n",
       "0   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.447214  0.0  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "10  0.280012  0.000000  0.000000  ...  0.280012  0.000000  0.0  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "12  0.000000  0.353553  0.353553  ...  0.000000  0.000000  0.0  0.353553   \n",
       "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.0  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.5  0.000000   \n",
       "\n",
       "          73        74        75        76        77        78  \n",
       "0   0.000000  0.361285  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.458638  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.249887  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.755067  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.458638  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.342836  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.280012  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.480535  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[15 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(allData['Processed_Comment'])\n",
    "\n",
    "allData_tfidf = pd.DataFrame(tfidf_matrix.todense())\n",
    "\n",
    "display(allData_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = allData_tfidf[:10]\n",
    "Y_train = allData['Polarity'][0:10]\n",
    "\n",
    "X_test = allData_tfidf[10:]\n",
    "Y_test = allData['Polarity'][10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:  [1 1 1 1 1]\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "decisionTree_tfidf = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "decisionTree_tfidf.fit(X_train , Y_train)\n",
    "Y_pred = decisionTree_tfidf.predict(X_test)\n",
    "print('Predicted values: ', end=' ')\n",
    "print(Y_pred)\n",
    "\n",
    "print('Accuracy:' , end=' ')\n",
    "print(accuracy_score(Y_test ,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Decision Tree Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_decisionTree = DecisionTreeClassifier(criterion = \"entropy\" , random_state = 100)\n",
    "full_decisionTree.fit(bag_of_words_all_data[:] , allData['Polarity'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(full_decisionTree, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTweet = 'This is a tweet it is a good tweet #happy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTweet = userTweet.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2335a5f5e290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muserTweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserTweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "userTweet = [w for w in x.split() if len(w)>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTweet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
